# Проектная работа на тему "Реализация масштабируемой системы мониторинга и аналитики в реальном времени на базе Vector, Apache Kafka и ClickHouse"
Данный проект демонстрирует решение для обработки логов событий безопасности с использованием контейнеризированной инфраструктуры. Решение включает генерацию событий, их передачу через брокер сообщений Kafka, обработку с помощью Vector и сохранение в ClickHouse для последующего анализа.
## Архитектура и компоненты

- **ClickHouse**  
  Хранение и аналитика логов. Контейнер развёрнут на основе образа [clickhouse/clickhouse-server](https://hub.docker.com/r/clickhouse/clickhouse-server) и на старте выполняет SQL-скрипты из папки `init-scripts` для создания необходимых таблиц (например, таблица `analytic_events_security` в базе данных `logs`).

- **Zookeeper**  
  Координация и управление кластером Kafka. Используется официальный образ [bitnami/zookeeper](https://hub.docker.com/r/bitnami/zookeeper).

- **Kafka**  
  Брокер сообщений, обеспечивающий обмен данными между компонентами. Контейнер работает на основе образа [bitnami/kafka](https://hub.docker.com/r/bitnami/kafka) с настройками авто-создания топиков. Топик `analytic_events_security` используется для передачи логов.

- **Генератор событий (event_generator)**  
  Python-скрипт, который генерирует фейковые JSON-логи с событиями безопасности. Используется библиотека Faker для создания случайных данных (имена пользователей, IP-адреса, типы событий и т.д.). Логи записываются в файл `/app/events.out`, который монтируется в volume для последующей обработки.

- **Vector для Kafka → ClickHouse (vector_clickhouse)**  
  Сервис на базе [Timber.io Vector](https://vector.dev) подписывается на топик `analytic_events_security` в Kafka, обрабатывает сообщения (например, добавляет временную метку и форматирует дату) и отправляет их в ClickHouse. Дополнительно данные могут сохраняться в виде файлов для резервного копирования.

- **Vector для File → Kafka (vector_kafka)**  
  Второй экземпляр Vector считывает данные из файла логов (сгенерированного event_generator), преобразует их (парсинг JSON) и публикует в топик `analytic_events_security` в Kafka.

# Обработка данных

## Генерация событий
Скрипт `event_generator.py` постоянно создаёт JSON-логи событий безопасности и записывает их в файл `/app/events.out`.

## Отправка в Kafka
`Vector` (конфигурация `vector_kafka.yaml`) считывает данные из файла, парсит JSON и публикует их в топик `analytic_events_security` в Kafka.

## Передача в ClickHouse
`Vector` (конфигурация `vector_clickhouse.yaml`) подписывается на топик Kafka, обогащает данные (например, добавляя временную метку) и сохраняет их в таблицу `analytic_events_security` базы данных `logs` в ClickHouse.

## Резервное копирование
Помимо отправки в ClickHouse, сырые данные из Kafka сохраняются в файл для возможности аудита или дополнительной обработки.

---

# Настройка и расширение

## ClickHouse
Скрипты в папке `init-scripts` отвечают за первоначальную настройку базы данных (создание таблиц и схем).

## Vector
Файлы `vector_clickhouse.yaml` и `vector_kafka.yaml` можно настраивать для изменения логики обработки данных, смены топиков или изменения параметров аутентификации.

## Генератор событий
Скрипт `event_generator.py` можно модифицировать, добавляя новые типы событий, изменяя формат логов или дополняя поля для более детальной информации.

---
# Заключение
Проект демонстрирует полный цикл обработки событий безопасности: от генерации логов до их передачи и сохранения в аналитической базе данных. Используемые технологии (`Docker`, `Kafka`, `Vector`, `ClickHouse`) позволяют создать масштабируемое и отказоустойчивое решение, которое легко адаптируется под задачи мониторинга и анализа.
