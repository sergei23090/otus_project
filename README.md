# Проектная работа на тему "Реализация масштабируемой системы мониторинга и аналитики в реальном времени на базе Vector, Apache Kafka и ClickHouse"

Реализация проекта по созданию масштабируемого производственного хранилища данных на базе ClickHouse с интеграцией Vector, Apache Kafka, Prometheus, Grafana и других компонентов. Ниже приведены конкретные цели реализации, подробное описание архитектуры с описанием всех контейнеров из docker-compose и разделение ключевых блоков на логические секции.

---

## Цели работы:

- **Обеспечить стабильную генерацию, маршрутизацию и трансформацию событий безопасности для аналитики**  
- **Организовать бесшовное взаимодействие между компонентами:**  
  - Генерация событий;
  - Передача сообщений через Apache Kafka;
  - Трансформация и отправка данных в ClickHouse с помощью Vector.

- **Развернуть сбор метрик с ключевых сервисов и их визуализацию с помощью Prometheus и Grafana, настроить дашборды для оперативного контроля.**  
  

- **Реализовать кластер ClickHouse, состоящий из 2 шардов, каждый из которых имеет 2 реплики, а также настроить Kafka с 3 брокерами, где каждый брокер имеет репликацию по 3 и 3 партиции, что обеспечивает высокую доступность и отказоустойчивость системы**  

---
# Установка и запуск

## Требования

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

## Установка и запуск

```
  git clone https://github.com/sergei23090/otus_project.git
```
```
  cd otus_project
```
```
  docker-compose up -d
```

## Просмотр логов генератора событий

```
  docker logs -f event_generator
```

### Подключение к Grafana дял просмотра дашбордов логов и с метрик
- В адресной строке:
  ```
    http://localhost:3000
  ```
- login
  ```
    admin
  ```
- password
  ```
    admin
  ```
### Для подключения к СУБД через DBeaver (балансировка через HAProxy)
- Адрес:
  ```
    http://localhost:8124
  ```
- login
  ```
    default
  ```
- password
  ```
    secret123
  ```
  
---

## Архитектура решения
![image](https://github.com/user-attachments/assets/49324a70-51b8-44fc-91d8-a54e4a8de5c7)


Проект построен на контейнеризированной инфраструктуре, описанной в файле `docker-compose.yml`. Каждый контейнер выполняет свою роль в общей системе. Ниже приведено описание основных контейнеров, разделённых по функциональным блокам.

### 1. Мониторинг и визуализация

- **Grafana**  
  *Образ:* `grafana/grafana:latest`  
  *Функция:* Визуализация метрик и создание дашбордов для контроля работы всех компонентов. Используются provisioning файлы и настройки в `grafana.ini`.  
  *Порты:* 3000 (доступ к веб-интерфейсу).

- **Prometheus**  
  *Образ:* `prom/prometheus:latest`  
  *Функция:* Сбор и хранение метрик с различных источников (ClickHouse, Kafka, Zookeeper и др.).  
  *Порты:* 9090, используется конфигурация из `prometheus.yml`.

- **Kafka Exporter**  
  *Образ:* `danielqsj/kafka-exporter`  
  *Функция:* Экспорт метрик из Apache Kafka для последующей визуализации в Prometheus.

- **Zookeeper Exporter**  
  *Образ:* `dabealu/zookeeper-exporter:latest`  
  *Функция:* Сбор метрик состояния Zookeeper, используемых Prometheus для мониторинга кластера.

---

### 2. Хранилище данных и балансировка нагрузки

- **ClickHouse Кластер**  
  *Образ:* `clickhouse/clickhouse-server:latest`  
  *Функция:* Высокопроизводительное аналитическое хранилище данных, реализованное в виде кластера, состоящего из **2 шардов**, где каждый шард имеет **2 реплики**. Каждый контейнер инициализируется с SQL-скриптами (из папки `init-scripts`) и объединяется в кластер через конфигурацию в `cluster_config.xml`.

- **HAProxy**  
  *Образ:* `haproxy:latest`  
  *Функция:* Балансировка нагрузки между инстансами ClickHouse. Обеспечивает доступ к кластеру по единому адресу и равномерное распределение запросов.

---

### 3. Сбор, маршрутизация и обработка событий

- **Event Generator**  
  *Образ:* Собран из Dockerfile (на основе Python)  
  *Функция:* Генерирует тестовые JSON-события логов безопасности с помощью скрипта `event_generator.py`. События записываются в файл, который монтируется как volume.

- **Vector (File → Kafka)**  
  *Образ:* `timberio/vector:latest-alpine`  
  *Функция:* Читает логи из файлов (сгенерированные Event Generator), парсит их и публикует в топик Kafka.   
  *Конфигурация:* Файл `vector/vector_kafka.yaml`.

- **Vector (Kafka → ClickHouse)**  
  *Образ:* `timberio/vector:latest-alpine`  
  *Функция:* Подписывается на топик Apache Kafka, выполняет преобразования (обогащение временной меткой, валидацию данных) и отправляет данные в ClickHouse.  
  *Конфигурация:* Файл `vector/vector_clickhouse.yaml`.

- **Vector для Docker Logs Kafka**  
  *Образ:* `timberio/vector:latest-alpine`  
  *Функция:* Сбор логов из Docker и отправка их в Kafka для централизованного логирования и дальнейшей аналитики.

---

### 4. Брокер сообщений и координация

- **Apache Kafka**  
  *Образ:* `bitnami/kafka:latest`  
  *Функция:* Обеспечивает высокодоступную передачу сообщений между компонентами. В системе **3 брокера** настроены с **3 репликациями** и **3 партициями**, что гарантирует высокую надежность и масштабируемость передачи данных.
  - **kafka1**
  - **kafka2**
  - **kafka3**

- **Zookeeper**  
  Два контейнера для координации:
  - **zookeeper** – для ClickHouse.
  - **zookeeper_kafka** – для Kafka.  
  *Образ:* `bitnami/zookeeper:latest`  
  *Функция:* Обеспечивают синхронизацию и управление состоянием кластера Kafka и ClickHouse.

---

### 5. Дополнительные сервисы

- **Vector Docker Logs Kafka**  
  *Образ:* `timberio/vector:latest-alpine`  
  *Функция:* Сбор логов Docker и их отправка в Kafka для централизации логирования.

- **Источники данных для Grafana**  
  Файлы `datasource-clickhouse.yaml` и `datasource-prometheus.yaml` настроены для подключения Grafana к ClickHouse и Prometheus соответственно.

---

## Структура проекта и файлы

- `docker-compose.yml` – Определение всех контейнеров и их взаимосвязей.
- `cluster_config.xml` – Конфигурация кластера ClickHouse, репликация и настройки Zookeeper.
- `event_generator.py` – Скрипт для генерации тестовых событий.
- Конфигурационные файлы Vector:  
  - `vector/vector_kafka.yaml`  
  - `vector/vector_clickhouse.yaml`
- Конфигурация Grafana:  
  - `grafana.ini`  
  - `dashboards.yaml`
- Источники данных Grafana:  
  - `datasource-clickhouse.yaml`  
  - `datasource-prometheus.yaml`
- `prometheus.yml` – Конфигурация Prometheus для сбора метрик.

---

## Итог

В ходе проекта реализовано высокопроизводительное, масштабируемое и отказоустойчивое решение для обработки и аналитики данных в реальном времени. Система охватывает полный цикл:
- **Генерация событий** (Event Generator),
- **Передача через Kafka** (3 брокера с 3 репликациями и 3 партициями),
- **Трансформация данных с помощью Vector** (с гибкой настройкой и мониторингом),
- **Хранение и аналитика в распределённом кластере ClickHouse** (2 шарда, по 2 реплики в каждом),
- **Мониторинг и визуализация** с помощью Prometheus и Grafana.

*Преимущества интеграции с Vector:*  
- **Возможность настраивать сложные преобразования данных до их отправки в Kafka или ClickHouse.**   
- **Встроенные возможности мониторинга позволяют быстро выявлять и устранять ошибки в обработке данных**  
- **Разделение процессов на независимые этапы (сбор, трансформация, маршрутизация) повышает отказоустойчивость и упрощает масштабирование.**
---

